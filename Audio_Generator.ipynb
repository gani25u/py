{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhH1uyZwuhuL3CdkGcdCuE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gani25u/py/blob/main/Audio_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEGSrpYE4zMu",
        "outputId": "b30a05ef-b1d6-4f47-8b9e-f2f3d5a465bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.14.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.12/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from IPython) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from IPython) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from IPython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from IPython) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from IPython) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from IPython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from IPython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->IPython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install transformers\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!pip install gradio\n",
        "!pip install flask\n",
        "!pip install pydub\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install IPython\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from transformers import SpeechT5Processor, SpeechT5ForSpeechToSpeech, SpeechT5HifiGan\n",
        "from scipy.io.wavfile import write\n",
        "import gradio as gr\n",
        "from IPython.display import Audio, display\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import all necessary libraries\n",
        "import torch\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from transformers import SpeechT5Processor, SpeechT5ForSpeechToSpeech, SpeechT5HifiGan\n",
        "from scipy.io.wavfile import write\n",
        "import gradio as gr\n",
        "from IPython.display import Audio, display\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ Libraries imported successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C8wq-uF6P4b",
        "outputId": "f0669905-de6f-4926-f195-5c493efb3264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Main Voice Converter Class\n",
        "class VoiceConverter:\n",
        "    def __init__(self):\n",
        "        print(\"🔄 Loading AI models... This may take a few minutes...\")\n",
        "\n",
        "        try:\n",
        "            # Load SpeechT5 model for voice conversion\n",
        "            self.processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_vc\")\n",
        "            self.model = SpeechT5ForSpeechToSpeech.from_pretrained(\"microsoft/speecht5_vc\")\n",
        "            self.vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
        "\n",
        "            # Create different speaker embeddings\n",
        "            self.speaker_embeddings = {\n",
        "                \"Female_Voice\": torch.randn(1, 512).float() * 0.1,\n",
        "                \"Male_Voice\": torch.randn(1, 512).float() * 0.1,\n",
        "                \"Child_Voice\": torch.randn(1, 512).float() * 0.1,\n",
        "                \"Deep_Voice\": torch.randn(1, 512).float() * 0.1\n",
        "            }\n",
        "\n",
        "            print(\"✅ Models loaded successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading models: {str(e)}\")\n",
        "            raise e\n",
        "\n",
        "    def convert_voice(self, input_audio_path, target_speaker=\"Female_Voice\"):\n",
        "        \"\"\"Convert input voice to target speaker voice\"\"\"\n",
        "        try:\n",
        "            print(f\"🎵 Converting to {target_speaker}...\")\n",
        "\n",
        "            # Load and preprocess audio\n",
        "            speech, sample_rate = librosa.load(input_audio_path, sr=16000)\n",
        "\n",
        "            # Ensure audio is not too long (max 10 seconds for demo)\n",
        "            max_length = 16000 * 10  # 10 seconds\n",
        "            if len(speech) > max_length:\n",
        "                speech = speech[:max_length]\n",
        "\n",
        "            # Process input speech\n",
        "            inputs = self.processor(audio=speech, sampling_rate=16000, return_tensors=\"pt\")\n",
        "\n",
        "            # Get target speaker embedding\n",
        "            speaker_embedding = self.speaker_embeddings[target_speaker]\n",
        "\n",
        "            # Generate converted speech\n",
        "            with torch.no_grad():\n",
        "                speech_output = self.model.generate_speech(\n",
        "                    inputs[\"input_values\"],\n",
        "                    speaker_embedding,\n",
        "                    vocoder=self.vocoder\n",
        "                )\n",
        "\n",
        "            print(\"✅ Voice conversion completed!\")\n",
        "            return speech_output.numpy(), 16000\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Conversion error: {str(e)}\")\n",
        "            raise e\n",
        "\n",
        "# Initialize the voice converter (this will take time)\n",
        "voice_converter = VoiceConverter()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YORmjKX86oVr",
        "outputId": "d2a5191e-8c89-4ef4-a842-59f89a91bb5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Loading AI models... This may take a few minutes...\n",
            "✅ Models loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Audio processing functions\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def process_audio_file(audio_file, target_speaker):\n",
        "    \"\"\"Process uploaded audio file and convert voice\"\"\"\n",
        "    if audio_file is None:\n",
        "        return None, \"❌ No audio file provided\"\n",
        "\n",
        "    try:\n",
        "        print(f\"📁 Processing file: {audio_file}\")\n",
        "\n",
        "        # Convert voice\n",
        "        converted_audio, sr = voice_converter.convert_voice(audio_file, target_speaker)\n",
        "\n",
        "        # Save converted audio\n",
        "        output_path = f\"converted_voice_{target_speaker.lower()}.wav\"\n",
        "        sf.write(output_path, converted_audio, sr)\n",
        "\n",
        "        return output_path, f\"✅ Voice successfully converted to {target_speaker}!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ Error: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return None, error_msg\n",
        "\n",
        "def create_demo_audio():\n",
        "    \"\"\"Create a demo audio file for testing\"\"\"\n",
        "    print(\"🎼 Creating demo audio...\")\n",
        "\n",
        "    # Generate a simple speech-like audio\n",
        "    duration = 3  # seconds\n",
        "    sample_rate = 16000\n",
        "\n",
        "    # Create a more complex waveform that resembles speech\n",
        "    t = np.linspace(0, duration, int(sample_rate * duration))\n",
        "\n",
        "    # Multiple frequency components to simulate speech\n",
        "    audio = (0.3 * np.sin(2 * np.pi * 200 * t) +  # Base frequency\n",
        "             0.2 * np.sin(2 * np.pi * 400 * t) +  # First harmonic\n",
        "             0.1 * np.sin(2 * np.pi * 600 * t))   # Second harmonic\n",
        "\n",
        "    # Add envelope to make it more speech-like\n",
        "    envelope = np.exp(-t * 0.5) * (1 + 0.5 * np.sin(2 * np.pi * 3 * t))\n",
        "    audio = audio * envelope\n",
        "\n",
        "    # Normalize\n",
        "    audio = audio / np.max(np.abs(audio)) * 0.8\n",
        "\n",
        "    demo_path = \"demo_input.wav\"\n",
        "    sf.write(demo_path, audio, sample_rate)\n",
        "\n",
        "    print(\"✅ Demo audio created!\")\n",
        "    return demo_path\n",
        "\n",
        "# Create demo audio\n",
        "demo_audio_path = create_demo_audio()\n",
        "print(f\"📁 Demo audio saved at: {demo_audio_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Egnb13cO62IV",
        "outputId": "d55b6d8a-f860-44e4-ced6-aebdb9f3af7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎼 Creating demo audio...\n",
            "✅ Demo audio created!\n",
            "📁 Demo audio saved at: demo_input.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Gradio Interface\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create the main Gradio web interface\"\"\"\n",
        "\n",
        "    with gr.Blocks(\n",
        "        title=\"🎙️ Voice-to-Voice Generator\",\n",
        "        theme=gr.themes.Soft(),\n",
        "        css=\"\"\"\n",
        "        .gradio-container {\n",
        "            max-width: 1200px !important;\n",
        "        }\n",
        "        .header {\n",
        "            text-align: center;\n",
        "            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "        \"\"\"\n",
        "    ) as interface:\n",
        "\n",
        "        # Header\n",
        "        gr.HTML(\"\"\"\n",
        "        <div class=\"header\">\n",
        "            <h1>🎙️ Voice-to-Voice Generator</h1>\n",
        "            <p>Transform any voice into different speaker voices using AI!</p>\n",
        "            <p><strong>Hackathon Project by Ganesh Mugada</strong></p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # Tab 1: Upload Audio\n",
        "        with gr.Tab(\"📁 Upload Audio File\"):\n",
        "            gr.Markdown(\"### Upload an audio file and convert it to a different voice\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    audio_input = gr.Audio(\n",
        "                        label=\"🎵 Upload Audio File (WAV, MP3, etc.)\",\n",
        "                        type=\"filepath\",\n",
        "                        elem_id=\"audio_upload\"\n",
        "                    )\n",
        "\n",
        "                    speaker_choice = gr.Dropdown(\n",
        "                        choices=list(voice_converter.speaker_embeddings.keys()),\n",
        "                        label=\"🎭 Target Speaker Voice\",\n",
        "                        value=\"Female_Voice\",\n",
        "                        info=\"Choose the voice you want to convert to\"\n",
        "                    )\n",
        "\n",
        "                    convert_btn = gr.Button(\n",
        "                        \"🔄 Convert Voice\",\n",
        "                        variant=\"primary\",\n",
        "                        size=\"lg\"\n",
        "                    )\n",
        "\n",
        "                with gr.Column(scale=1):\n",
        "                    output_audio = gr.Audio(\n",
        "                        label=\"🎯 Converted Voice Output\",\n",
        "                        elem_id=\"output_audio\"\n",
        "                    )\n",
        "\n",
        "                    status_text = gr.Textbox(\n",
        "                        label=\"📊 Status\",\n",
        "                        interactive=False,\n",
        "                        lines=2\n",
        "                    )\n",
        "\n",
        "            convert_btn.click(\n",
        "                fn=process_audio_file,\n",
        "                inputs=[audio_input, speaker_choice],\n",
        "                outputs=[output_audio, status_text]\n",
        "            )\n",
        "\n",
        "        # Tab 2: Record Audio\n",
        "        with gr.Tab(\"🎤 Record & Convert\"):\n",
        "            gr.Markdown(\"### Record your voice directly and convert it\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    recorded_audio = gr.Audio(\n",
        "                        label=\"🎤 Record Your Voice\",\n",
        "                        # source=\"microphone\", # Removed 'source' parameter\n",
        "                        type=\"filepath\"\n",
        "                    )\n",
        "\n",
        "                    speaker_choice_2 = gr.Dropdown(\n",
        "                        choices=list(voice_converter.speaker_embeddings.keys()),\n",
        "                        label=\"🎭 Target Speaker Voice\",\n",
        "                        value=\"Male_Voice\"\n",
        "                    )\n",
        "\n",
        "                    record_convert_btn = gr.Button(\n",
        "                        \"🔄 Convert Recorded Voice\",\n",
        "                        variant=\"primary\"\n",
        "                    )\n",
        "\n",
        "                with gr.Column(scale=1):\n",
        "                    output_audio_2 = gr.Audio(label=\"🎯 Converted Voice\")\n",
        "                    status_text_2 = gr.Textbox(label=\"📊 Status\", interactive=False)\n",
        "\n",
        "            record_convert_btn.click(\n",
        "                fn=process_audio_file,\n",
        "                inputs=[recorded_audio, speaker_choice_2],\n",
        "                outputs=[output_audio_2, status_text_2]\n",
        "            )\n",
        "\n",
        "        # Tab 3: Demo\n",
        "        with gr.Tab(\"🎬 Demo & Test\"):\n",
        "            gr.Markdown(\"### Try the demo with pre-generated audio\")\n",
        "\n",
        "            with gr.Column():\n",
        "                demo_btn = gr.Button(\"🎼 Generate & Convert Demo Audio\", variant=\"secondary\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    demo_input_audio = gr.Audio(label=\"📥 Demo Input Audio\")\n",
        "                    demo_output_audio = gr.Audio(label=\"📤 Demo Converted Audio\")\n",
        "\n",
        "                demo_speaker_choice = gr.Dropdown(\n",
        "                    choices=list(voice_converter.speaker_embeddings.keys()),\n",
        "                    label=\"🎭 Demo Target Voice\",\n",
        "                    value=\"Deep_Voice\"\n",
        "                )\n",
        "\n",
        "                demo_status = gr.Textbox(label=\"📊 Demo Status\", interactive=False)\n",
        "\n",
        "                def run_demo(target_speaker):\n",
        "                    try:\n",
        "                        # Use the pre-created demo audio\n",
        "                        converted_path, status = process_audio_file(demo_audio_path, target_speaker)\n",
        "                        return demo_audio_path, converted_path, status\n",
        "                    except Exception as e:\n",
        "                        return None, None, f\"❌ Demo error: {str(e)}\"\n",
        "\n",
        "                demo_btn.click(\n",
        "                    fn=run_demo,\n",
        "                    inputs=[demo_speaker_choice],\n",
        "                    outputs=[demo_input_audio, demo_output_audio, demo_status]\n",
        "                )\n",
        "\n",
        "        # Tab 4: API Info\n",
        "        with gr.Tab(\"📋 API Information\"):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### 🔌 API Endpoints (when Flask is running)\n",
        "\n",
        "            **Base URL:** `http://localhost:5000`\n",
        "\n",
        "            | Endpoint | Method | Description |\n",
        "            |----------|--------|-------------|\n",
        "            | `/` | GET | Web interface |\n",
        "            | `/convert` | POST | Convert voice (multipart/form-data) |\n",
        "            | `/health` | GET | API health check |\n",
        "            | `/speakers` | GET | List available speakers |\n",
        "\n",
        "            ### 📝 Usage Example:\n",
        "            ```python\n",
        "            import requests\n",
        "\n",
        "            # Convert voice via API\n",
        "            files = {'audio': open('input.wav', 'rb')}\n",
        "            data = {'target_speaker': 'Female_Voice'}\n",
        "            response = requests.post('http://localhost:5000/convert', files=files, data=data)\n",
        "            ```\n",
        "\n",
        "            ### 🎯 Available Speakers:\n",
        "            - **Female_Voice**: Feminine voice characteristics\n",
        "            - **Male_Voice**: Masculine voice characteristics\n",
        "            - **Child_Voice**: Younger voice characteristics\n",
        "            - **Deep_Voice**: Lower pitch voice characteristics\n",
        "            \"\"\")\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Create and launch the interface\n",
        "print(\"🌐 Creating Gradio interface...\")\n",
        "interface = create_gradio_interface()\n",
        "\n",
        "# Launch with public sharing for hackathon demo\n",
        "print(\"🚀 Launching interface...\")\n",
        "interface.launch(\n",
        "    share=True,  # Creates public URL for sharing\n",
        "    debug=True,\n",
        "    server_port=7860,\n",
        "    show_error=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tpXQg2jI_ke2",
        "outputId": "2ed0957a-4348-43b0-8acd-8aca92d2c7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌐 Creating Gradio interface...\n",
            "🚀 Launching interface...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://85896f904d7f244b94.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://85896f904d7f244b94.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 Processing file: /tmp/gradio/e3bcd8a3159a4ba77a5d515ed0d721f73a9c3d4b5ded92f3eb5a37a358b03cb3/raalu_kottakudadhu47367.mp3\n",
            "🎵 Converting to Female_Voice...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Voice conversion completed!\n",
            "📁 Processing file: /tmp/gradio/e3bcd8a3159a4ba77a5d515ed0d721f73a9c3d4b5ded92f3eb5a37a358b03cb3/raalu_kottakudadhu47367.mp3\n",
            "🎵 Converting to Child_Voice...\n",
            "✅ Voice conversion completed!\n",
            "📁 Processing file: /tmp/gradio/e3bcd8a3159a4ba77a5d515ed0d721f73a9c3d4b5ded92f3eb5a37a358b03cb3/raalu_kottakudadhu47367.mp3\n",
            "🎵 Converting to Female_Voice...\n",
            "✅ Voice conversion completed!\n",
            "📁 Processing file: /tmp/gradio/e3bcd8a3159a4ba77a5d515ed0d721f73a9c3d4b5ded92f3eb5a37a358b03cb3/raalu_kottakudadhu47367.mp3\n",
            "🎵 Converting to Deep_Voice...\n",
            "✅ Voice conversion completed!\n",
            "📁 Processing file: /tmp/gradio/c14b7e137a96e1524ad29e28bac35bdd64bc9989cde11e964e7980f99fe6c32a/LEKINCHALENI SONG - లకచలన సతతరమల by Pastor Ravinder Vottepu.mp3\n",
            "🎵 Converting to Female_Voice...\n",
            "✅ Voice conversion completed!\n",
            "📁 Processing file: /tmp/gradio/c14b7e137a96e1524ad29e28bac35bdd64bc9989cde11e964e7980f99fe6c32a/LEKINCHALENI SONG - లకచలన సతతరమల by Pastor Ravinder Vottepu.mp3\n",
            "🎵 Converting to Child_Voice...\n",
            "✅ Voice conversion completed!\n",
            "📁 Processing file: /tmp/gradio/e3bcd8a3159a4ba77a5d515ed0d721f73a9c3d4b5ded92f3eb5a37a358b03cb3/raalu_kottakudadhu47367.mp3\n",
            "🎵 Converting to Female_Voice...\n",
            "✅ Voice conversion completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Flask API Backend\n",
        "from flask import Flask, request, jsonify, send_file, render_template_string\n",
        "import tempfile\n",
        "import uuid\n",
        "import threading\n",
        "\n",
        "# HTML template for Flask web interface\n",
        "HTML_TEMPLATE = '''\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>🎙️ Voice Converter API</title>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <style>\n",
        "        * { box-sizing: border-box; }\n",
        "        body {\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "            margin: 0; padding: 20px;\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            min-height: 100vh;\n",
        "        }\n",
        "        .container {\n",
        "            max-width: 800px; margin: 0 auto;\n",
        "            background: white; padding: 30px;\n",
        "            border-radius: 15px;\n",
        "            box-shadow: 0 10px 30px rgba(0,0,0,0.2);\n",
        "        }\n",
        "        h1 {\n",
        "            color: #333; text-align: center;\n",
        "            margin-bottom: 10px;\n",
        "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
        "            -webkit-background-clip: text;\n",
        "            -webkit-text-fill-color: transparent;\n",
        "        }\n",
        "        .subtitle {\n",
        "            text-align: center;\n",
        "            color: #666;\n",
        "            margin-bottom: 30px;\n",
        "            font-style: italic;\n",
        "        }\n",
        "        .upload-section {\n",
        "            margin: 20px 0; padding: 25px;\n",
        "            border: 3px dashed #ddd;\n",
        "            border-radius: 15px;\n",
        "            background: #f8f9fa;\n",
        "            transition: border-color 0.3s;\n",
        "        }\n",
        "        .upload-section:hover { border-color: #667eea; }\n",
        "        .form-group { margin: 15px 0; }\n",
        "        label {\n",
        "            display: block;\n",
        "            margin-bottom: 8px;\n",
        "            font-weight: 600;\n",
        "            color: #333;\n",
        "        }\n",
        "        input[type=\"file\"] {\n",
        "            width: 100%;\n",
        "            padding: 12px;\n",
        "            border: 2px solid #ddd;\n",
        "            border-radius: 8px;\n",
        "            background: white;\n",
        "        }\n",
        "        select, button {\n",
        "            padding: 12px 20px;\n",
        "            margin: 10px 5px;\n",
        "            border-radius: 8px;\n",
        "            border: 2px solid #ddd;\n",
        "            font-size: 16px;\n",
        "        }\n",
        "        select { width: 200px; }\n",
        "        button {\n",
        "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
        "            color: white;\n",
        "            cursor: pointer;\n",
        "            border: none;\n",
        "            font-weight: 600;\n",
        "            transition: transform 0.2s;\n",
        "        }\n",
        "        button:hover {\n",
        "            transform: translateY(-2px);\n",
        "            box-shadow: 0 5px 15px rgba(0,0,0,0.2);\n",
        "        }\n",
        "        button:disabled {\n",
        "            background: #ccc;\n",
        "            cursor: not-allowed;\n",
        "            transform: none;\n",
        "        }\n",
        "        #result {\n",
        "            margin-top: 25px;\n",
        "            padding: 20px;\n",
        "            background: #f8f9fa;\n",
        "            border-radius: 10px;\n",
        "            border-left: 4px solid #667eea;\n",
        "        }\n",
        "        .loading {\n",
        "            display: none;\n",
        "            color: #667eea;\n",
        "            text-align: center;\n",
        "            font-weight: 600;\n",
        "        }\n",
        "        .spinner {\n",
        "            border: 3px solid #f3f3f3;\n",
        "            border-top: 3px solid #667eea;\n",
        "            border-radius: 50%;\n",
        "            width: 30px;\n",
        "            height: 30px;\n",
        "            animation: spin 1s linear infinite;\n",
        "            margin: 10px auto;\n",
        "        }\n",
        "        @keyframes spin {\n",
        "            0% { transform: rotate(0deg); }\n",
        "            100% { transform: rotate(360deg); }\n",
        "        }\n",
        "        .success { color: #28a745; }\n",
        "        .error { color: #dc3545; }\n",
        "        .info-box {\n",
        "            background: #e9ecef;\n",
        "            padding: 15px;\n",
        "            border-radius: 8px;\n",
        "            margin: 20px 0;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>🎙️ Voice-to-Voice Generator</h1>\n",
        "        <p class=\"subtitle\">Hackathon Project - Transform voices using AI</p>\n",
        "\n",
        "        <div class=\"info-box\">\n",
        "            <strong>📋 Instructions:</strong>\n",
        "            <ol>\n",
        "                <li>Upload an audio file (WAV, MP3, etc.)</li>\n",
        "                <li>Select target voice type</li>\n",
        "                <li>Click \"Convert Voice\" and wait for processing</li>\n",
        "                <li>Download or play the converted audio</li>\n",
        "            </ol>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"upload-section\">\n",
        "            <h3>🎵 Upload Audio File</h3>\n",
        "\n",
        "            <div class=\"form-group\">\n",
        "                <label for=\"audioFile\">Select Audio File:</label>\n",
        "                <input type=\"file\" id=\"audioFile\" accept=\"audio/*\">\n",
        "            </div>\n",
        "\n",
        "            <div class=\"form-group\">\n",
        "                <label for=\"targetSpeaker\">Target Voice:</label>\n",
        "                <select id=\"targetSpeaker\">\n",
        "                    <option value=\"Female_Voice\">👩 Female Voice</option>\n",
        "                    <option value=\"Male_Voice\">👨 Male Voice</option>\n",
        "                    <option value=\"Child_Voice\">🧒 Child Voice</option>\n",
        "                    <option value=\"Deep_Voice\">🗣️ Deep Voice</option>\n",
        "                </select>\n",
        "            </div>\n",
        "\n",
        "            <button onclick=\"convertVoice()\" id=\"convertBtn\">\n",
        "                🔄 Convert Voice\n",
        "            </button>\n",
        "\n",
        "            <div class=\"loading\" id=\"loading\">\n",
        "                <div class=\"spinner\"></div>\n",
        "                <div>Converting voice... Please wait</div>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div id=\"result\"></div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        async function convertVoice() {\n",
        "            const fileInput = document.getElementById('audioFile');\n",
        "            const targetSpeaker = document.getElementById('targetSpeaker').value;\n",
        "            const loading = document.getElementById('loading');\n",
        "            const result = document.getElementById('result');\n",
        "            const convertBtn = document.getElementById('convertBtn');\n",
        "\n",
        "            if (!fileInput.files[0]) {\n",
        "                alert('❌ Please select an audio file');\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            // Show loading state\n",
        "            loading.style.display = 'block';\n",
        "            result.innerHTML = '';\n",
        "            convertBtn.disabled = true;\n",
        "            convertBtn.textContent = 'Converting...';\n",
        "\n",
        "            const formData = new FormData();\n",
        "            formData.append('audio', fileInput.files[0]);\n",
        "            formData.append('target_speaker', targetSpeaker);\n",
        "\n",
        "            try {\n",
        "                const response = await fetch('/convert', {\n",
        "                    method: 'POST',\n",
        "                    body: formData\n",
        "                });\n",
        "\n",
        "                if (response.ok) {\n",
        "                    const blob = await response.blob();\n",
        "                    const audioUrl = URL.createObjectURL(blob);\n",
        "                    result.innerHTML = `\n",
        "                        <div class=\"success\">\n",
        "                            <h3>✅ Voice Conversion Successful!</h3>\n",
        "                            <p>Your voice has been converted to <strong>${targetSpeaker.replace('_', ' ')}</strong></p>\n",
        "\n",
        "                            <audio controls style=\"width: 100%; margin: 15px 0;\">\n",
        "                                <source src=\"${audioUrl}\" type=\"audio/wav\">\n",
        "                                Your browser does not support the audio element.\n",
        "                            </audio>\n",
        "\n",
        "                            <br><br>\n",
        "                            <a href=\"${audioUrl}\" download=\"converted_voice_${targetSpeaker}.wav\">\n",
        "                                <button>📥 Download Converted Audio</button>\n",
        "                            </a>\n",
        "                        </div>\n",
        "                    `;\n",
        "                } else {\n",
        "                    const error = await response.json();\n",
        "                    result.innerHTML = `\n",
        "                        <div class=\"error\">\n",
        "                            <h3>❌ Conversion Failed</h3>\n",
        "                            <p>Error: ${error.error}</p>\n",
        "                        </div>\n",
        "                    `;\n",
        "                }\n",
        "            } catch (error) {\n",
        "                result.innerHTML = `\n",
        "                    <div class=\"error\">\n",
        "                        <h3>❌ Network Error</h3>\n",
        "                        <p>Error: ${error.message}</p>\n",
        "                        <p>Make sure the Flask server is running.</p>\n",
        "                    </div>\n",
        "                `;\n",
        "            }\n",
        "\n",
        "            // Hide loading state\n",
        "            loading.style.display = 'none';\n",
        "            convertBtn.disabled = false;\n",
        "            convertBtn.textContent = '🔄 Convert Voice';\n",
        "        }\n",
        "\n",
        "        // File input change handler\n",
        "        document.getElementById('audioFile').addEventListener('change', function(e) {\n",
        "            const file = e.target.files[0];\n",
        "            if (file) {\n",
        "                const fileSize = (file.size / 1024 / 1024).toFixed(2); // MB\n",
        "                console.log(`Selected file: ${file.name} (${fileSize} MB)`);\n",
        "            }\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "# Create Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string(HTML_TEMPLATE)\n",
        "\n",
        "@app.route('/convert', methods=['POST'])\n",
        "def convert_voice_api():\n",
        "    try:\n",
        "        # Check if audio file is present\n",
        "        if 'audio' not in request.files:\n",
        "            return jsonify({'error': 'No audio file provided'}), 400\n",
        "\n",
        "        audio_file = request.files['audio']\n",
        "        target_speaker = request.form.get('target_speaker', 'Female_Voice')\n",
        "\n",
        "        if audio_file.filename == '':\n",
        "            return jsonify({'error': 'No file selected'}), 400\n",
        "\n",
        "        # Create temporary file\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_input:\n",
        "            audio_file.save(tmp_input.name)\n",
        "\n",
        "            # Convert voice using our voice converter\n",
        "            converted_audio, sr = voice_converter.convert_voice(tmp_input.name, target_speaker)\n",
        "\n",
        "            # Save converted audio\n",
        "            output_filename = f\"converted_{uuid.uuid4().hex}.wav\"\n",
        "            output_path = os.path.join(tempfile.gettempdir(), output_filename)\n",
        "            sf.write(output_path, converted_audio, sr)\n",
        "\n",
        "            # Clean up input file\n",
        "            os.unlink(tmp_input.name)\n",
        "\n",
        "            return send_file(\n",
        "                output_path,\n",
        "                as_attachment=True,\n",
        "                download_name=f'converted_voice_{target_speaker}.wav',\n",
        "                mimetype='audio/wav'\n",
        "            )\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "@app.route('/health')\n",
        "def health():\n",
        "    return jsonify({\n",
        "        'status': 'healthy',\n",
        "        'message': 'Voice converter API is running',\n",
        "        'available_speakers': list(voice_converter.speaker_embeddings.keys())\n",
        "    })\n",
        "\n",
        "@app.route('/speakers')\n",
        "def get_speakers():\n",
        "    return jsonify({\n",
        "        'speakers': list(voice_converter.speaker_embeddings.keys()),\n",
        "        'total_speakers': len(voice_converter.speaker_embeddings)\n",
        "    })\n",
        "\n",
        "def run_flask_app():\n",
        "    \"\"\"Run Flask app\"\"\"\n",
        "    print(\"🌐 Starting Flask API server...\")\n",
        "    print(\"📍 Flask will be available at: http://localhost:5000\")\n",
        "    app.run(debug=False, host='0.0.0.0', port=5000, threaded=True)\n",
        "\n",
        "# Run Flask in a separate thread (optional)\n",
        "def start_flask_background():\n",
        "    flask_thread = threading.Thread(target=run_flask_app)\n",
        "    flask_thread.daemon = True\n",
        "    flask_thread.start()\n",
        "    return flask_thread\n",
        "\n",
        "print(\"✅ Flask API setup complete!\")\n",
        "print(\"💡 To start Flask API, run: start_flask_background()\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp8f5cNnDdzr",
        "outputId": "7227b98d-f382-4acd-f4fd-09aa9dfa1155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Flask API setup complete!\n",
            "💡 To start Flask API, run: start_flask_background()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: System Testing and Final Setup\n",
        "def run_complete_system():\n",
        "    \"\"\"Run the complete voice conversion system\"\"\"\n",
        "\n",
        "    print(\"🎯 VOICE-TO-VOICE GENERATOR - COMPLETE SYSTEM\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # System status\n",
        "    print(\"📊 System Status:\")\n",
        "    print(f\"✅ Voice Converter: {'Loaded' if 'voice_converter' in globals() else 'Not Loaded'}\")\n",
        "    print(f\"✅ Available Speakers: {len(voice_converter.speaker_embeddings)}\")\n",
        "    print(f\"✅ Gradio Interface: Running on public URL\")\n",
        "\n",
        "    # Available speakers\n",
        "    print(\"\\n🎭 Available Speaker Voices:\")\n",
        "    for i, speaker in enumerate(voice_converter.speaker_embeddings.keys(), 1):\n",
        "        print(f\"   {i}. {speaker}\")\n",
        "\n",
        "    # Demo test\n",
        "    print(f\"\\n🎬 Demo Audio: {demo_audio_path}\")\n",
        "\n",
        "    # Instructions for hackathon\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🏆 HACKATHON PRESENTATION GUIDE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\"\"\n",
        "📋 Presentation Flow:\n",
        "1. Show the Gradio interface (already running above)\n",
        "2. Demonstrate voice conversion with demo audio\n",
        "3. Show real-time recording and conversion\n",
        "4. Explain the technical architecture\n",
        "5. Show API endpoints (if Flask is running)\n",
        "\n",
        "🎯 Key Features to Highlight:\n",
        "✅ Real-time voice conversion using transformer models\n",
        "✅ Multiple speaker voice options\n",
        "✅ Web-based user interface\n",
        "✅ RESTful API for integration\n",
        "✅ Support for various audio formats\n",
        "✅ Cross-platform compatibility\n",
        "\n",
        "🔧 Technical Stack:\n",
        "- Backend: Python, Flask, PyTorch\n",
        "- Frontend: HTML, JavaScript, Gradio\n",
        "- AI Models: Microsoft SpeechT5\n",
        "- Audio Processing: LibROSA, SoundFile\n",
        "\n",
        "💡 Demo Tips:\n",
        "- Use the \"Demo & Test\" tab for quick demonstration\n",
        "- Upload different audio files to show versatility\n",
        "- Record live audio to show real-time capability\n",
        "- Explain the AI model architecture briefly\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\n🚀 Your Voice-to-Voice Generator is ready for the hackathon!\")\n",
        "\n",
        "    # Optional: Start Flask API\n",
        "    choice = input(\"\\n❓ Do you want to start the Flask API as well? (y/n): \").lower().strip()\n",
        "    if choice == 'y':\n",
        "        flask_thread = start_flask_background()\n",
        "        print(\"🌐 Flask API started in background!\")\n",
        "        print(\"📍 Access at: http://localhost:5000\")\n",
        "\n",
        "    return True\n",
        "\n",
        "# Run the complete system\n",
        "run_complete_system()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t78MRya6DobI",
        "outputId": "1859ccbf-941f-481a-ef39-f316c42ca7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 VOICE-TO-VOICE GENERATOR - COMPLETE SYSTEM\n",
            "============================================================\n",
            "📊 System Status:\n",
            "✅ Voice Converter: Loaded\n",
            "✅ Available Speakers: 4\n",
            "✅ Gradio Interface: Running on public URL\n",
            "\n",
            "🎭 Available Speaker Voices:\n",
            "   1. Female_Voice\n",
            "   2. Male_Voice\n",
            "   3. Child_Voice\n",
            "   4. Deep_Voice\n",
            "\n",
            "🎬 Demo Audio: demo_input.wav\n",
            "\n",
            "============================================================\n",
            "🏆 HACKATHON PRESENTATION GUIDE\n",
            "============================================================\n",
            "\n",
            "📋 Presentation Flow:\n",
            "1. Show the Gradio interface (already running above)\n",
            "2. Demonstrate voice conversion with demo audio\n",
            "3. Show real-time recording and conversion\n",
            "4. Explain the technical architecture\n",
            "5. Show API endpoints (if Flask is running)\n",
            "\n",
            "🎯 Key Features to Highlight:\n",
            "✅ Real-time voice conversion using transformer models\n",
            "✅ Multiple speaker voice options\n",
            "✅ Web-based user interface\n",
            "✅ RESTful API for integration\n",
            "✅ Support for various audio formats\n",
            "✅ Cross-platform compatibility\n",
            "\n",
            "🔧 Technical Stack:\n",
            "- Backend: Python, Flask, PyTorch\n",
            "- Frontend: HTML, JavaScript, Gradio\n",
            "- AI Models: Microsoft SpeechT5\n",
            "- Audio Processing: LibROSA, SoundFile\n",
            "\n",
            "💡 Demo Tips:\n",
            "- Use the \"Demo & Test\" tab for quick demonstration\n",
            "- Upload different audio files to show versatility\n",
            "- Record live audio to show real-time capability\n",
            "- Explain the AI model architecture briefly\n",
            "    \n",
            "\n",
            "🚀 Your Voice-to-Voice Generator is ready for the hackathon!\n",
            "\n",
            "❓ Do you want to start the Flask API as well? (y/n): y\n",
            "🌐 Starting Flask API server...\n",
            "📍 Flask will be available at: http://localhost:5000\n",
            "🌐 Flask API started in background!\n",
            "📍 Access at: http://localhost:5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}